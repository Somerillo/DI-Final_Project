{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title: Time Series Analysis of Pennsylvania and Illinois Weather, Energy Consumption, and Flu Contagion (2013–2015)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, we aim to identify and explore temporal patterns, correlations, and potential causal relationships between weather conditions, energy consumption, and flu contagion across Pennsylvania and Illinois from 2013 to 2015. By analyzing these interrelated datasets, we hope to derive insights that can inform stakeholders in public health and energy management.\n",
    "\n",
    "### Objectives\n",
    "- Analyze daily/hourly weather data to identify trends and seasonal patterns.\n",
    "- Examine hourly energy consumption data to understand usage patterns in relation to weather.\n",
    "- Investigate weekly flu contagion data to determine correlations with weather and energy consumption.\n",
    "- Utilize statistical modeling techniques to assess interdependencies among the datasets.\n",
    "\n",
    "### Key Datasets\n",
    "1. **USA Weather Dataset (2013–2015)**:\n",
    "   - Temporal granularity: Hourly\n",
    "   - Variables of interest: Temperature.\n",
    "\n",
    "2. **PJM Historic Energy Consumption**:\n",
    "   - Temporal granularity: Hourly\n",
    "   - Scope: Energy usage data for Pennsylvania (Duquesne Light) and Illinois (ComEd).\n",
    "\n",
    "3. **Flu Contagion Dataset by State (2013–2015)**:\n",
    "   - Temporal granularity: Weekly\n",
    "   - Variables: Influenza-like illness (ILI) [activity](https://www.cdc.gov/mmwr/volumes/67/wr/mm6722a4.htm) in the USA.\n",
    "\n",
    "This notebook will guide you through the data ingestion, preparation, exploratory data analysis (EDA), time series modeling, and visualization phases of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation and Analysis\n",
    "import pandas as pd  # For data manipulation and analysis using DataFrames\n",
    "import numpy as np   # For numerical operations and handling arrays\n",
    "\n",
    "# Statistical Analysis\n",
    "import scipy.stats as stats  # For statistical tests and distributions\n",
    "from statsmodels.tsa.stattools import adfuller  # For stationarity tests\n",
    "\n",
    "# Time Series Analysis\n",
    "from statsmodels.tsa.arima.model import ARIMA  # For ARIMA modeling\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose  # For seasonal decomposition of time series\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split  # For splitting datasets into training and testing sets\n",
    "from sklearn.ensemble import RandomForestRegressor  # For regression tasks\n",
    "import xgboost as xgb  # For gradient boosting models\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt  # For creating static visualizations\n",
    "import seaborn as sns            # For enhanced statistical visualizations\n",
    "import plotly.express as px      # For interactive plots (optional)\n",
    "\n",
    "# Date and Time Handling\n",
    "from datetime import datetime     # For date/time manipulation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion/Wrangling\n",
    "\n",
    "We begin by retrieving the relevant dataframes for our job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather dataset, granularity in hours. We are only interested in two states. This dataset is the one imposing the time dataframe in our study. As we are interested in its influence on energy consumption and flu activity, we isolate only the temperature (originally in Kelvin degrees).\n",
    "\n",
    "Note: for this particular dataset we only have Pittsburgh and Chicago as representative cities for the states of Pennsylvania and Illinois respectivelly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Vancouver</th>\n",
       "      <th>Portland</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>Seattle</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>San Diego</th>\n",
       "      <th>Las Vegas</th>\n",
       "      <th>Phoenix</th>\n",
       "      <th>Albuquerque</th>\n",
       "      <th>...</th>\n",
       "      <th>Philadelphia</th>\n",
       "      <th>New York</th>\n",
       "      <th>Montreal</th>\n",
       "      <th>Boston</th>\n",
       "      <th>Beersheba</th>\n",
       "      <th>Tel Aviv District</th>\n",
       "      <th>Eilat</th>\n",
       "      <th>Haifa</th>\n",
       "      <th>Nahariyya</th>\n",
       "      <th>Jerusalem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01 12:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>284.630000</td>\n",
       "      <td>282.080000</td>\n",
       "      <td>289.480000</td>\n",
       "      <td>281.800000</td>\n",
       "      <td>291.870000</td>\n",
       "      <td>291.530000</td>\n",
       "      <td>293.410000</td>\n",
       "      <td>296.600000</td>\n",
       "      <td>285.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>285.630000</td>\n",
       "      <td>288.220000</td>\n",
       "      <td>285.830000</td>\n",
       "      <td>287.170000</td>\n",
       "      <td>307.590000</td>\n",
       "      <td>305.470000</td>\n",
       "      <td>310.580000</td>\n",
       "      <td>304.4</td>\n",
       "      <td>304.4</td>\n",
       "      <td>303.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01 14:00:00</td>\n",
       "      <td>284.629041</td>\n",
       "      <td>282.083252</td>\n",
       "      <td>289.474993</td>\n",
       "      <td>281.797217</td>\n",
       "      <td>291.868186</td>\n",
       "      <td>291.533501</td>\n",
       "      <td>293.403141</td>\n",
       "      <td>296.608509</td>\n",
       "      <td>285.154558</td>\n",
       "      <td>...</td>\n",
       "      <td>285.663208</td>\n",
       "      <td>288.247676</td>\n",
       "      <td>285.834650</td>\n",
       "      <td>287.186092</td>\n",
       "      <td>307.590000</td>\n",
       "      <td>304.310000</td>\n",
       "      <td>310.495769</td>\n",
       "      <td>304.4</td>\n",
       "      <td>304.4</td>\n",
       "      <td>303.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01 15:00:00</td>\n",
       "      <td>284.626998</td>\n",
       "      <td>282.091866</td>\n",
       "      <td>289.460618</td>\n",
       "      <td>281.789833</td>\n",
       "      <td>291.862844</td>\n",
       "      <td>291.543355</td>\n",
       "      <td>293.392177</td>\n",
       "      <td>296.631487</td>\n",
       "      <td>285.233952</td>\n",
       "      <td>...</td>\n",
       "      <td>285.756824</td>\n",
       "      <td>288.326940</td>\n",
       "      <td>285.847790</td>\n",
       "      <td>287.231672</td>\n",
       "      <td>307.391513</td>\n",
       "      <td>304.281841</td>\n",
       "      <td>310.411538</td>\n",
       "      <td>304.4</td>\n",
       "      <td>304.4</td>\n",
       "      <td>303.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01 16:00:00</td>\n",
       "      <td>284.624955</td>\n",
       "      <td>282.100481</td>\n",
       "      <td>289.446243</td>\n",
       "      <td>281.782449</td>\n",
       "      <td>291.857503</td>\n",
       "      <td>291.553209</td>\n",
       "      <td>293.381213</td>\n",
       "      <td>296.654466</td>\n",
       "      <td>285.313345</td>\n",
       "      <td>...</td>\n",
       "      <td>285.850440</td>\n",
       "      <td>288.406203</td>\n",
       "      <td>285.860929</td>\n",
       "      <td>287.277251</td>\n",
       "      <td>307.145200</td>\n",
       "      <td>304.238015</td>\n",
       "      <td>310.327308</td>\n",
       "      <td>304.4</td>\n",
       "      <td>304.4</td>\n",
       "      <td>303.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45248</th>\n",
       "      <td>2017-11-29 20:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>280.820000</td>\n",
       "      <td>293.550000</td>\n",
       "      <td>292.150000</td>\n",
       "      <td>289.540000</td>\n",
       "      <td>294.710000</td>\n",
       "      <td>285.720000</td>\n",
       "      <td>...</td>\n",
       "      <td>290.240000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275.130000</td>\n",
       "      <td>288.080000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45249</th>\n",
       "      <td>2017-11-29 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>282.890000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281.650000</td>\n",
       "      <td>295.680000</td>\n",
       "      <td>292.740000</td>\n",
       "      <td>290.610000</td>\n",
       "      <td>295.590000</td>\n",
       "      <td>286.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>289.240000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>274.130000</td>\n",
       "      <td>286.020000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45250</th>\n",
       "      <td>2017-11-29 22:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283.390000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>282.750000</td>\n",
       "      <td>295.960000</td>\n",
       "      <td>292.580000</td>\n",
       "      <td>291.340000</td>\n",
       "      <td>296.250000</td>\n",
       "      <td>286.440000</td>\n",
       "      <td>...</td>\n",
       "      <td>286.780000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273.480000</td>\n",
       "      <td>283.940000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45251</th>\n",
       "      <td>2017-11-29 23:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283.020000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>282.960000</td>\n",
       "      <td>295.650000</td>\n",
       "      <td>292.610000</td>\n",
       "      <td>292.150000</td>\n",
       "      <td>297.150000</td>\n",
       "      <td>286.140000</td>\n",
       "      <td>...</td>\n",
       "      <td>284.570000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>272.480000</td>\n",
       "      <td>282.170000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45252</th>\n",
       "      <td>2017-11-30 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>282.280000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283.040000</td>\n",
       "      <td>294.930000</td>\n",
       "      <td>291.400000</td>\n",
       "      <td>291.640000</td>\n",
       "      <td>297.150000</td>\n",
       "      <td>284.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>283.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>271.800000</td>\n",
       "      <td>280.650000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45253 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime   Vancouver    Portland  San Francisco     Seattle  \\\n",
       "0      2012-10-01 12:00:00         NaN         NaN            NaN         NaN   \n",
       "1      2012-10-01 13:00:00  284.630000  282.080000     289.480000  281.800000   \n",
       "2      2012-10-01 14:00:00  284.629041  282.083252     289.474993  281.797217   \n",
       "3      2012-10-01 15:00:00  284.626998  282.091866     289.460618  281.789833   \n",
       "4      2012-10-01 16:00:00  284.624955  282.100481     289.446243  281.782449   \n",
       "...                    ...         ...         ...            ...         ...   \n",
       "45248  2017-11-29 20:00:00         NaN  282.000000            NaN  280.820000   \n",
       "45249  2017-11-29 21:00:00         NaN  282.890000            NaN  281.650000   \n",
       "45250  2017-11-29 22:00:00         NaN  283.390000            NaN  282.750000   \n",
       "45251  2017-11-29 23:00:00         NaN  283.020000            NaN  282.960000   \n",
       "45252  2017-11-30 00:00:00         NaN  282.280000            NaN  283.040000   \n",
       "\n",
       "       Los Angeles   San Diego   Las Vegas     Phoenix  Albuquerque  ...  \\\n",
       "0              NaN         NaN         NaN         NaN          NaN  ...   \n",
       "1       291.870000  291.530000  293.410000  296.600000   285.120000  ...   \n",
       "2       291.868186  291.533501  293.403141  296.608509   285.154558  ...   \n",
       "3       291.862844  291.543355  293.392177  296.631487   285.233952  ...   \n",
       "4       291.857503  291.553209  293.381213  296.654466   285.313345  ...   \n",
       "...            ...         ...         ...         ...          ...  ...   \n",
       "45248   293.550000  292.150000  289.540000  294.710000   285.720000  ...   \n",
       "45249   295.680000  292.740000  290.610000  295.590000   286.450000  ...   \n",
       "45250   295.960000  292.580000  291.340000  296.250000   286.440000  ...   \n",
       "45251   295.650000  292.610000  292.150000  297.150000   286.140000  ...   \n",
       "45252   294.930000  291.400000  291.640000  297.150000   284.700000  ...   \n",
       "\n",
       "       Philadelphia    New York    Montreal      Boston   Beersheba  \\\n",
       "0               NaN         NaN         NaN         NaN         NaN   \n",
       "1        285.630000  288.220000  285.830000  287.170000  307.590000   \n",
       "2        285.663208  288.247676  285.834650  287.186092  307.590000   \n",
       "3        285.756824  288.326940  285.847790  287.231672  307.391513   \n",
       "4        285.850440  288.406203  285.860929  287.277251  307.145200   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "45248    290.240000         NaN  275.130000  288.080000         NaN   \n",
       "45249    289.240000         NaN  274.130000  286.020000         NaN   \n",
       "45250    286.780000         NaN  273.480000  283.940000         NaN   \n",
       "45251    284.570000         NaN  272.480000  282.170000         NaN   \n",
       "45252    283.420000         NaN  271.800000  280.650000         NaN   \n",
       "\n",
       "       Tel Aviv District       Eilat  Haifa  Nahariyya  Jerusalem  \n",
       "0                    NaN  309.100000    NaN        NaN        NaN  \n",
       "1             305.470000  310.580000  304.4      304.4      303.5  \n",
       "2             304.310000  310.495769  304.4      304.4      303.5  \n",
       "3             304.281841  310.411538  304.4      304.4      303.5  \n",
       "4             304.238015  310.327308  304.4      304.4      303.5  \n",
       "...                  ...         ...    ...        ...        ...  \n",
       "45248                NaN         NaN    NaN        NaN        NaN  \n",
       "45249                NaN         NaN    NaN        NaN        NaN  \n",
       "45250                NaN         NaN    NaN        NaN        NaN  \n",
       "45251                NaN         NaN    NaN        NaN        NaN  \n",
       "45252                NaN         NaN    NaN        NaN        NaN  \n",
       "\n",
       "[45253 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = r'sources/historical_hourly_weather_data- 2012_to_2017/temperature.csv'\n",
    "df = pd.read_csv(path)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>pittsburgh_temp</th>\n",
       "      <th>chicago_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01 12:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>284.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01 14:00:00</td>\n",
       "      <td>281.024767</td>\n",
       "      <td>284.054691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01 15:00:00</td>\n",
       "      <td>281.088319</td>\n",
       "      <td>284.177412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01 16:00:00</td>\n",
       "      <td>281.151870</td>\n",
       "      <td>284.300133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45248</th>\n",
       "      <td>2017-11-29 20:00:00</td>\n",
       "      <td>285.300000</td>\n",
       "      <td>281.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45249</th>\n",
       "      <td>2017-11-29 21:00:00</td>\n",
       "      <td>285.330000</td>\n",
       "      <td>281.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45250</th>\n",
       "      <td>2017-11-29 22:00:00</td>\n",
       "      <td>282.910000</td>\n",
       "      <td>281.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45251</th>\n",
       "      <td>2017-11-29 23:00:00</td>\n",
       "      <td>280.140000</td>\n",
       "      <td>280.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45252</th>\n",
       "      <td>2017-11-30 00:00:00</td>\n",
       "      <td>279.190000</td>\n",
       "      <td>278.460000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45253 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime  pittsburgh_temp  chicago_temp\n",
       "0     2012-10-01 12:00:00              NaN           NaN\n",
       "1     2012-10-01 13:00:00       281.000000    284.010000\n",
       "2     2012-10-01 14:00:00       281.024767    284.054691\n",
       "3     2012-10-01 15:00:00       281.088319    284.177412\n",
       "4     2012-10-01 16:00:00       281.151870    284.300133\n",
       "...                   ...              ...           ...\n",
       "45248 2017-11-29 20:00:00       285.300000    281.340000\n",
       "45249 2017-11-29 21:00:00       285.330000    281.690000\n",
       "45250 2017-11-29 22:00:00       282.910000    281.070000\n",
       "45251 2017-11-29 23:00:00       280.140000    280.060000\n",
       "45252 2017-11-30 00:00:00       279.190000    278.460000\n",
       "\n",
       "[45253 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_temperature = df[['datetime', 'Pittsburgh', 'Chicago']].copy()\n",
    "\n",
    "# export it as CSV\n",
    "df_temperature.to_csv('raw_temperature.csv', index=False)\n",
    "\n",
    "# change col names\n",
    "df_temperature.columns = ['datetime', 'pittsburgh_temp', 'chicago_temp']\n",
    "\n",
    "# change 'datetime' format\n",
    "df_temperature['datetime'] = pd.to_datetime(df_temperature['datetime'])\n",
    "\n",
    "display(df_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## df_temperature NaN values: \n",
      "datetime           0\n",
      "pittsburgh_temp    3\n",
      "chicago_temp       3\n",
      "dtype: int64\n",
      "\n",
      "## df_temperature dates duplicated values: 0\n"
     ]
    }
   ],
   "source": [
    "# for completitude we count NaNs and duplicates\n",
    "# the few NaNs will be absorbed later on the average\n",
    "print(f'## df_temperature NaN values: \\n{df_temperature.isna().sum()}\\n')\n",
    "print(f'## df_temperature dates duplicated values: {df_temperature['datetime'].duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Unique years in temperature dataframe: [2012 2013 2014 2015 2016 2017]\n",
      "## Unique months in temperature dataframe: [10 11 12  1  2  3  4  5  6  7  8  9]\n",
      "## Unique days in temperature dataframe: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31]\n",
      "## Unique hour in temperature dataframe: [12 13 14 15 16 17 18 19 20 21 22 23  0  1  2  3  4  5  6  7  8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "# check unique values in temperature dataframe\n",
    "unique_years_temperature = df_temperature['datetime'].dt.year.unique()\n",
    "print(\"## Unique years in temperature dataframe:\", unique_years_temperature)\n",
    "\n",
    "unique_months_temperature = df_temperature['datetime'].dt.month.unique()\n",
    "print(\"## Unique months in temperature dataframe:\", unique_months_temperature)\n",
    "\n",
    "unique_days_temperature = df_temperature['datetime'].dt.day.unique()\n",
    "print(\"## Unique days in temperature dataframe:\", unique_days_temperature)\n",
    "\n",
    "unique_hour_temperature = df_temperature['datetime'].dt.hour.unique()\n",
    "print(\"## Unique hour in temperature dataframe:\", unique_hour_temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the electrical energy consumption by local statal companies, we have a dataset for Duquesne Light Co. (DUQ) and Commonwealth Edison (ComEd). The problem (for our analysis) is the interconnected energy distribution network: we have regional (not city) energy load:\n",
    "\n",
    "**Duquesne Light Company** primarily provides electricity to southwestern Pennsylvania, specifically serving the greater Pittsburgh area and parts of Allegheny and Beaver counties. The utility serves approximately 600,000 customers across an 817 square mile service area, with about 90% of its service area being residential [[1]](https://www.electricchoice.com/utilities/duquesne-light/), [[2]](https://www.chooseenergy.com/utilities/duquesne-light-co-pa/), [[3]](https://electricityplans.com/pennsylvania/utilities/duquesne-light-company/).\n",
    "\n",
    "**Commonwealth Edison (ComEd)** is the largest electric utility in Illinois, serving more than 4,000,000 customers across northern Illinois, which represents approximately 70% of the state's population. The company's service territory covers about 11,400 square miles, stretching from the Wisconsin border to the north, Iowa border to the west, Indiana border to the east, and as far south as Iroquois County. ComEd, a unit of Exelon Corporation, manages over 90,000 miles of power lines and has been providing electric service to the region for more than 100 years [[4]](https://www.exeloncorp.com/companies/comed), [[5]](https://www.ilcma.org/friends-of-ilcma/comed/), [[6]](https://en.wikipedia.org/wiki/Commonwealth_Edison).\n",
    "\n",
    "To bridge the connection between weather and energy datasets, we can hypothesize that state-level temperature trends are closely aligned with the temperature variations observed in their primary metropolitan areas. This assumption allows us to use city temperature data as a reliable proxy for regional weather conditions, facilitating more granular analysis of energy consumption patterns in relation to temperature fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>DUQ_MW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-12-31 01:00:00</td>\n",
       "      <td>1458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-12-31 02:00:00</td>\n",
       "      <td>1377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-12-31 03:00:00</td>\n",
       "      <td>1351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-12-31 04:00:00</td>\n",
       "      <td>1336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-12-31 05:00:00</td>\n",
       "      <td>1356.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime  DUQ_MW\n",
       "0  2005-12-31 01:00:00  1458.0\n",
       "1  2005-12-31 02:00:00  1377.0\n",
       "2  2005-12-31 03:00:00  1351.0\n",
       "3  2005-12-31 04:00:00  1336.0\n",
       "4  2005-12-31 05:00:00  1356.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>COMED_MW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-31 01:00:00</td>\n",
       "      <td>9970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-31 02:00:00</td>\n",
       "      <td>9428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-31 03:00:00</td>\n",
       "      <td>9059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-31 04:00:00</td>\n",
       "      <td>8817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-31 05:00:00</td>\n",
       "      <td>8743.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime  COMED_MW\n",
       "0  2011-12-31 01:00:00    9970.0\n",
       "1  2011-12-31 02:00:00    9428.0\n",
       "2  2011-12-31 03:00:00    9059.0\n",
       "3  2011-12-31 04:00:00    8817.0\n",
       "4  2011-12-31 05:00:00    8743.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import energy datasets\n",
    "path1 = r'sources\\hourly_energy_consumption\\DUQ_hourly.csv'\n",
    "path2 = r'sources\\hourly_energy_consumption\\COMED_hourly.csv'\n",
    "df_pennsylvania = pd.read_csv(path1)\n",
    "df_illinois = pd.read_csv(path2)\n",
    "\n",
    "# check df structure\n",
    "display(df_pennsylvania.head())\n",
    "print()\n",
    "display(df_illinois.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although [Pennsylvania](https://www.macrotrends.net/global-metrics/states/pennsylvania/population) and [Illinois](https://www.macrotrends.net/global-metrics/states/illinois/population) have similar populations, there is a magnitude order in energy load.\n",
    "\n",
    "| Year | Pennsylvania | Illinois    |\n",
    "|------|--------------|-------------|\n",
    "| 2012 | 12,763,536   | 12,875,280  |\n",
    "| 2013 | 12,773,801   | 12,882,250  |\n",
    "| 2014 | 12,787,209   | 12,880,552  |\n",
    "| 2015 | 12,802,503   | 12,859,585  |\n",
    "| 2016 | 12,784,227   | 12,821,709  |\n",
    "| 2017 | 12,805,537   | 12,779,893  |\n",
    "\n",
    "\n",
    "So to normalize the electric energy load, we will need to divide by the amount of clients of each company:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Duquesne_kW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-12-31 01:00:00</td>\n",
       "      <td>2.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-12-31 02:00:00</td>\n",
       "      <td>2.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-12-31 03:00:00</td>\n",
       "      <td>2.251667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-12-31 04:00:00</td>\n",
       "      <td>2.226667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-12-31 05:00:00</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119063</th>\n",
       "      <td>2018-01-01 20:00:00</td>\n",
       "      <td>3.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119064</th>\n",
       "      <td>2018-01-01 21:00:00</td>\n",
       "      <td>3.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119065</th>\n",
       "      <td>2018-01-01 22:00:00</td>\n",
       "      <td>3.151667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119066</th>\n",
       "      <td>2018-01-01 23:00:00</td>\n",
       "      <td>3.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119067</th>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "      <td>2.868333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119068 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime  Duquesne_kW\n",
       "0       2005-12-31 01:00:00     2.430000\n",
       "1       2005-12-31 02:00:00     2.295000\n",
       "2       2005-12-31 03:00:00     2.251667\n",
       "3       2005-12-31 04:00:00     2.226667\n",
       "4       2005-12-31 05:00:00     2.260000\n",
       "...                     ...          ...\n",
       "119063  2018-01-01 20:00:00     3.270000\n",
       "119064  2018-01-01 21:00:00     3.233333\n",
       "119065  2018-01-01 22:00:00     3.151667\n",
       "119066  2018-01-01 23:00:00     3.033333\n",
       "119067  2018-01-02 00:00:00     2.868333\n",
       "\n",
       "[119068 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>ComEdison_kW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-31 01:00:00</td>\n",
       "      <td>2.49250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-31 02:00:00</td>\n",
       "      <td>2.35700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-31 03:00:00</td>\n",
       "      <td>2.26475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-31 04:00:00</td>\n",
       "      <td>2.20425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-31 05:00:00</td>\n",
       "      <td>2.18575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66492</th>\n",
       "      <td>2018-01-01 20:00:00</td>\n",
       "      <td>3.46450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66493</th>\n",
       "      <td>2018-01-01 21:00:00</td>\n",
       "      <td>3.43950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66494</th>\n",
       "      <td>2018-01-01 22:00:00</td>\n",
       "      <td>3.40675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66495</th>\n",
       "      <td>2018-01-01 23:00:00</td>\n",
       "      <td>3.33400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66496</th>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "      <td>3.20400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66497 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Datetime  ComEdison_kW\n",
       "0      2011-12-31 01:00:00       2.49250\n",
       "1      2011-12-31 02:00:00       2.35700\n",
       "2      2011-12-31 03:00:00       2.26475\n",
       "3      2011-12-31 04:00:00       2.20425\n",
       "4      2011-12-31 05:00:00       2.18575\n",
       "...                    ...           ...\n",
       "66492  2018-01-01 20:00:00       3.46450\n",
       "66493  2018-01-01 21:00:00       3.43950\n",
       "66494  2018-01-01 22:00:00       3.40675\n",
       "66495  2018-01-01 23:00:00       3.33400\n",
       "66496  2018-01-02 00:00:00       3.20400\n",
       "\n",
       "[66497 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# manipulate energy datasets\n",
    "df_pennsylvania_pop = df_pennsylvania.copy()\n",
    "df_pennsylvania_pop['Duquesne_kW'] = df_pennsylvania_pop['DUQ_MW'] / 600 # divide by customers and convert to kW\n",
    "df_pennsylvania_pop.drop(columns='DUQ_MW', inplace=True)\n",
    "display(df_pennsylvania_pop)\n",
    "print()\n",
    "\n",
    "df_illinois_pop = df_illinois.copy()\n",
    "df_illinois_pop['ComEdison_kW'] = df_illinois_pop['COMED_MW'] / 4000 # divide by customers and convert to kW\n",
    "df_illinois_pop.drop(columns='COMED_MW', inplace=True)\n",
    "display(df_illinois_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some duplicated values, much possible due to summer time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Pensylvania missing values: \n",
      "Datetime       0\n",
      "Duquesne_kW    0\n",
      "dtype: int64\n",
      "\n",
      "## Illinois missing values: \n",
      "Datetime        0\n",
      "ComEdison_kW    0\n",
      "dtype: int64\n",
      "\n",
      "## Pensylvania duplicated values: \n",
      "4\n",
      "\n",
      "## Illinois duplicated values: \n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# check missing values\n",
    "print(f'## Pensylvania missing values: \\n{df_pennsylvania_pop.isna().sum()}')\n",
    "print()\n",
    "print(f'## Illinois missing values: \\n{df_illinois_pop.isna().sum()}')\n",
    "print()\n",
    "\n",
    "# check duplicates\n",
    "print(f'## Pensylvania duplicated values: \\n{df_pennsylvania_pop['Datetime'].duplicated().sum()}')\n",
    "print()\n",
    "print(f'## Illinois duplicated values: \\n{df_illinois_pop['Datetime'].duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Pensylvania duplicated values: \n",
      "0\n",
      "\n",
      "## Illinois duplicated values: \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# remove duplicates\n",
    "df_pennsylvania_pop = df_pennsylvania_pop.drop_duplicates(subset='Datetime')\n",
    "df_illinois_pop = df_illinois_pop.drop_duplicates(subset='Datetime')\n",
    "\n",
    "# check duplicates\n",
    "print(f'## Pensylvania duplicated values: \\n{df_pennsylvania_pop['Datetime'].duplicated().sum()}')\n",
    "print()\n",
    "print(f'## Illinois duplicated values: \\n{df_illinois_pop['Datetime'].duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Unique years in Pennsylvania dataframe: [2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018]\n",
      "## Unique years in Illinois dataframe: [2011 2012 2013 2014 2015 2016 2017 2018]\n"
     ]
    }
   ],
   "source": [
    "# ensure 'Datetime' is in datetime format\n",
    "df_pennsylvania_pop['Datetime'] = pd.to_datetime(df_pennsylvania_pop['Datetime'])\n",
    "df_illinois_pop['Datetime'] = pd.to_datetime(df_illinois_pop['Datetime'])\n",
    "\n",
    "# check unique years in Pennsylvania dataframe\n",
    "unique_years_pennsylvania = df_pennsylvania_pop['Datetime'].dt.year.unique()\n",
    "print(\"## Unique years in Pennsylvania dataframe:\", unique_years_pennsylvania)\n",
    "\n",
    "# check unique years in Illinois dataframe\n",
    "unique_years_illinois = df_illinois_pop['Datetime'].dt.year.unique()\n",
    "print(\"## Unique years in Illinois dataframe:\", unique_years_illinois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need only the time period specified by the weather data. We achieve that with a left inner join on the temperature dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>pittsburgh_temp</th>\n",
       "      <th>chicago_temp</th>\n",
       "      <th>Duquesne_kW</th>\n",
       "      <th>ComEdison_kW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01 12:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.716667</td>\n",
       "      <td>2.82550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>284.010000</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>2.85650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01 14:00:00</td>\n",
       "      <td>281.024767</td>\n",
       "      <td>284.054691</td>\n",
       "      <td>2.745000</td>\n",
       "      <td>2.88050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01 15:00:00</td>\n",
       "      <td>281.088319</td>\n",
       "      <td>284.177412</td>\n",
       "      <td>2.716667</td>\n",
       "      <td>2.89350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01 16:00:00</td>\n",
       "      <td>281.151870</td>\n",
       "      <td>284.300133</td>\n",
       "      <td>2.711667</td>\n",
       "      <td>2.87225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45241</th>\n",
       "      <td>2017-11-29 20:00:00</td>\n",
       "      <td>285.300000</td>\n",
       "      <td>281.340000</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>3.04275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45242</th>\n",
       "      <td>2017-11-29 21:00:00</td>\n",
       "      <td>285.330000</td>\n",
       "      <td>281.690000</td>\n",
       "      <td>2.676667</td>\n",
       "      <td>2.99950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45243</th>\n",
       "      <td>2017-11-29 22:00:00</td>\n",
       "      <td>282.910000</td>\n",
       "      <td>281.070000</td>\n",
       "      <td>2.591667</td>\n",
       "      <td>2.92025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45244</th>\n",
       "      <td>2017-11-29 23:00:00</td>\n",
       "      <td>280.140000</td>\n",
       "      <td>280.060000</td>\n",
       "      <td>2.461667</td>\n",
       "      <td>2.78700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45245</th>\n",
       "      <td>2017-11-30 00:00:00</td>\n",
       "      <td>279.190000</td>\n",
       "      <td>278.460000</td>\n",
       "      <td>2.306667</td>\n",
       "      <td>2.59775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45246 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime  pittsburgh_temp  chicago_temp  Duquesne_kW  \\\n",
       "0     2012-10-01 12:00:00              NaN           NaN     2.716667   \n",
       "1     2012-10-01 13:00:00       281.000000    284.010000     2.733333   \n",
       "2     2012-10-01 14:00:00       281.024767    284.054691     2.745000   \n",
       "3     2012-10-01 15:00:00       281.088319    284.177412     2.716667   \n",
       "4     2012-10-01 16:00:00       281.151870    284.300133     2.711667   \n",
       "...                   ...              ...           ...          ...   \n",
       "45241 2017-11-29 20:00:00       285.300000    281.340000     2.690000   \n",
       "45242 2017-11-29 21:00:00       285.330000    281.690000     2.676667   \n",
       "45243 2017-11-29 22:00:00       282.910000    281.070000     2.591667   \n",
       "45244 2017-11-29 23:00:00       280.140000    280.060000     2.461667   \n",
       "45245 2017-11-30 00:00:00       279.190000    278.460000     2.306667   \n",
       "\n",
       "       ComEdison_kW  \n",
       "0           2.82550  \n",
       "1           2.85650  \n",
       "2           2.88050  \n",
       "3           2.89350  \n",
       "4           2.87225  \n",
       "...             ...  \n",
       "45241       3.04275  \n",
       "45242       2.99950  \n",
       "45243       2.92025  \n",
       "45244       2.78700  \n",
       "45245       2.59775  \n",
       "\n",
       "[45246 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'## Shape of df_temperature:(45253, 3)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'## Shape of df_energy:(45246, 5)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## df_energy missing values: \n",
      "datetime           0\n",
      "pittsburgh_temp    3\n",
      "chicago_temp       3\n",
      "Duquesne_kW        0\n",
      "ComEdison_kW       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# merge temp and duqesne\n",
    "df_energy = pd.merge(df_temperature, df_pennsylvania_pop, left_on='datetime', right_on='Datetime', how='inner')\n",
    "df_energy.drop(columns='Datetime', inplace=True)\n",
    "\n",
    "# merge with common edison\n",
    "df_energy = pd.merge(df_energy, df_illinois_pop, left_on='datetime', right_on='Datetime', how='inner')\n",
    "df_energy.drop(columns='Datetime', inplace=True)\n",
    "\n",
    "# check shape\n",
    "display(df_energy)\n",
    "display(f'## Shape of df_temperature:{df_temperature.shape}')\n",
    "display(f'## Shape of df_energy:{df_energy.shape}')\n",
    "\n",
    "# check missin values\n",
    "print(f'## df_energy missing values: \\n{df_energy.isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing an intersection on the temperature datetime, the number of rows was reduced by 7 due to the use of daylight saving time. And is the same reason why we have 3 missing temperature values. This would imply a 1 hour phase shift on the modeling during daylight saving time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flu dataset, pay attention to its granularity in weeks. The relationship between the weather dataset and flu activity dataset is not straight forward and need grouping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](<erd diagram.png>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'sources\\fluview\\StateDatabySeason55_54,53,52,57,56.csv'\n",
    "df = pd.read_csv(path)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu = df[(df['STATENAME'] == 'Pennsylvania') | (df['STATENAME'] == 'Illinois')].copy()\n",
    "display(df_flu)\n",
    "df_flu.to_csv('raw_flu.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Devs_Institute",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
